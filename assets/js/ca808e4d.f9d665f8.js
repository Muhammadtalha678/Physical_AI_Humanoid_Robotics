"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[8294],{907:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>a,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"week-13/gpt-conversational-ai","title":"Integrating GPT Models for Conversational AI","description":"Large Language Models (LLMs) like GPT have revolutionized conversational AI systems. This section covers the integration of GPT models into humanoid robotics systems, enabling natural and contextually aware interactions.","source":"@site/docs/week-13/gpt-conversational-ai.md","sourceDirName":"week-13","slug":"/week-13/gpt-conversational-ai","permalink":"/Physical-AI-Humanoid-Robotics/docs/week-13/gpt-conversational-ai","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/week-13/gpt-conversational-ai.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Integrating GPT Models for Conversational AI"},"sidebar":"tutorialSidebar","previous":{"title":"Natural Human-Robot Interaction Design","permalink":"/Physical-AI-Humanoid-Robotics/docs/week-11-12/human-robot-interaction"},"next":{"title":"Speech Recognition and Natural Language Understanding","permalink":"/Physical-AI-Humanoid-Robotics/docs/week-13/speech-recognition"}}');var s=t(4848),r=t(8453);const a={sidebar_position:1,title:"Integrating GPT Models for Conversational AI"},i="Integrating GPT Models for Conversational AI",l={},c=[{value:"Introduction to LLMs in Robotics",id:"introduction-to-llms-in-robotics",level:2},{value:"Why LLMs for Robotics?",id:"why-llms-for-robotics",level:3},{value:"Challenges in LLM-Robot Integration",id:"challenges-in-llm-robot-integration",level:3},{value:"GPT Model Fundamentals",id:"gpt-model-fundamentals",level:2},{value:"Architecture Overview",id:"architecture-overview",level:3},{value:"Prompt Engineering for Robotics",id:"prompt-engineering-for-robotics",level:3},{value:"Context Management",id:"context-management",level:2},{value:"Conversation History",id:"conversation-history",level:3},{value:"Task and World State Context",id:"task-and-world-state-context",level:3},{value:"Safety and Control Mechanisms",id:"safety-and-control-mechanisms",level:2},{value:"Action Validation",id:"action-validation",level:3},{value:"Response Filtering",id:"response-filtering",level:3},{value:"Integration Patterns",id:"integration-patterns",level:2},{value:"Async Processing Pattern",id:"async-processing-pattern",level:3},{value:"Context-Aware Response Generation",id:"context-aware-response-generation",level:3},{value:"Practical Implementation Considerations",id:"practical-implementation-considerations",level:2},{value:"Latency Management",id:"latency-management",level:3},{value:"Memory Management",id:"memory-management",level:3},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Code Examples",id:"code-examples",level:2},{value:"Exercises",id:"exercises",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"integrating-gpt-models-for-conversational-ai",children:"Integrating GPT Models for Conversational AI"})}),"\n",(0,s.jsx)(n.p,{children:"Large Language Models (LLMs) like GPT have revolutionized conversational AI systems. This section covers the integration of GPT models into humanoid robotics systems, enabling natural and contextually aware interactions."}),"\n",(0,s.jsx)(n.h2,{id:"introduction-to-llms-in-robotics",children:"Introduction to LLMs in Robotics"}),"\n",(0,s.jsx)(n.h3,{id:"why-llms-for-robotics",children:"Why LLMs for Robotics?"}),"\n",(0,s.jsx)(n.p,{children:"Large Language Models bring several advantages to robotic systems:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Natural Language Understanding"}),": Ability to understand complex, ambiguous, or colloquial language"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Contextual Reasoning"}),": Understanding of context, world knowledge, and common sense"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Flexible Interaction"}),": Ability to handle unexpected questions and requests"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Knowledge Integration"}),": Access to vast amounts of world knowledge"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"challenges-in-llm-robot-integration",children:"Challenges in LLM-Robot Integration"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Real-time Constraints"}),": LLM inference can be slow"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Embodied Grounding"}),": Connecting language to physical actions and environment"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Safety and Control"}),": Ensuring robot actions are safe and appropriate"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Context Management"}),": Maintaining conversation and task context"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"gpt-model-fundamentals",children:"GPT Model Fundamentals"}),"\n",(0,s.jsx)(n.h3,{id:"architecture-overview",children:"Architecture Overview"}),"\n",(0,s.jsx)(n.p,{children:"GPT models are based on the Transformer architecture with autoregressive training:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\n\nclass GPTRobotInterface:\n    def __init__(self, model_name=\'gpt2\'):\n        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n\n        # Add padding token if it doesn\'t exist\n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n\n    def encode_text(self, text):\n        """\n        Encode text for model input\n        """\n        return self.tokenizer.encode(text, return_tensors=\'pt\')\n\n    def decode_output(self, token_ids):\n        """\n        Decode model output to text\n        """\n        return self.tokenizer.decode(token_ids[0], skip_special_tokens=True)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"prompt-engineering-for-robotics",children:"Prompt Engineering for Robotics"}),"\n",(0,s.jsx)(n.p,{children:"Effective prompting is crucial for robotics applications:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class RobotPromptEngineer:\n    def __init__(self):\n        self.system_prompt = """\n        You are a helpful robotic assistant. You have access to a humanoid robot with the following capabilities:\n        - Navigation: can move to locations (go_to(location))\n        - Manipulation: can pick up and place objects (pick_up(object), place_at(location))\n        - Speech: can speak responses (speak(text))\n        - Perception: can recognize objects and people (recognize_object(target))\n\n        Always respond with executable actions for the robot or with a natural language response.\n        Be concise, safe, and helpful.\n        """\n\n    def create_robot_prompt(self, user_input, robot_state, available_actions):\n        """\n        Create a contextual prompt for the robot\n        """\n        prompt = f"{self.system_prompt}\\n\\n"\n        prompt += f"Current robot state: {robot_state}\\n"\n        prompt += f"Available actions: {available_actions}\\n"\n        prompt += f"User input: {user_input}\\n"\n        prompt += "Robot response:"\n\n        return prompt\n\n    def parse_model_response(self, response):\n        """\n        Parse the model response into robot actions\n        """\n        # Look for action patterns in the response\n        import re\n\n        # Example: Extract navigation commands\n        nav_match = re.search(r"go_to\\(([^)]+)\\)", response)\n        if nav_match:\n            return {\n                \'action\': \'navigation\',\n                \'target\': nav_match.group(1),\n                \'raw_response\': response\n            }\n\n        # Example: Extract manipulation commands\n        pick_match = re.search(r"pick_up\\(([^)]+)\\)", response)\n        if pick_match:\n            return {\n                \'action\': \'manipulation\',\n                \'target\': pick_match.group(1),\n                \'raw_response\': response\n            }\n\n        # Default: speech response\n        return {\n            \'action\': \'speak\',\n            \'text\': response,\n            \'raw_response\': response\n        }\n'})}),"\n",(0,s.jsx)(n.h2,{id:"context-management",children:"Context Management"}),"\n",(0,s.jsx)(n.h3,{id:"conversation-history",children:"Conversation History"}),"\n",(0,s.jsx)(n.p,{children:"Maintaining conversation context is essential for coherent interactions:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class ConversationManager:\n    def __init__(self, max_history=10):\n        self.max_history = max_history\n        self.conversation_history = []\n        self.context_summary = ""\n\n    def add_turn(self, user_input, robot_response):\n        """\n        Add a turn to the conversation history\n        """\n        turn = {\n            \'user\': user_input,\n            \'robot\': robot_response,\n            \'timestamp\': self.get_current_time()\n        }\n        self.conversation_history.append(turn)\n\n        # Keep only recent history\n        if len(self.conversation_history) > self.max_history:\n            self.conversation_history.pop(0)\n\n        # Update context summary periodically\n        if len(self.conversation_history) % 3 == 0:\n            self.update_context_summary()\n\n    def get_context_prompt(self):\n        """\n        Get the context to include in prompts\n        """\n        context = "Recent conversation:\\n"\n        for i, turn in enumerate(self.conversation_history[-5:]):  # Last 5 turns\n            context += f"User: {turn[\'user\']}\\n"\n            context += f"Robot: {turn[\'robot\']}\\n"\n\n        if self.context_summary:\n            context += f"\\nConversation summary: {self.context_summary}\\n"\n\n        return context\n\n    def update_context_summary(self):\n        """\n        Create a summary of the conversation so far\n        """\n        # In practice, this would use a smaller model to summarize\n        # For this example, we\'ll just concatenate recent topics\n        recent_inputs = [turn[\'user\'] for turn in self.conversation_history[-3:]]\n        self.context_summary = " ".join(recent_inputs)[:200]  # Truncate to 200 chars\n'})}),"\n",(0,s.jsx)(n.h3,{id:"task-and-world-state-context",children:"Task and World State Context"}),"\n",(0,s.jsx)(n.p,{children:"Integrating task and world state into the conversation:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class WorldStateContext:\n    def __init__(self):\n        self.objects = {}\n        self.locations = {}\n        self.robot_state = {}\n        self.current_task = None\n\n    def update_object(self, obj_id, properties):\n        """\n        Update information about an object\n        """\n        if obj_id not in self.objects:\n            self.objects[obj_id] = {}\n        self.objects[obj_id].update(properties)\n\n    def get_world_context(self):\n        """\n        Get current world state for context\n        """\n        context = "Current world state:\\n"\n\n        # Objects in environment\n        if self.objects:\n            context += "Visible objects:\\n"\n            for obj_id, props in self.objects.items():\n                context += f"- {obj_id}: {props}\\n"\n\n        # Robot state\n        if self.robot_state:\n            context += f"Robot location: {self.robot_state.get(\'location\', \'unknown\')}\\n"\n            context += f"Robot battery: {self.robot_state.get(\'battery\', 100)}%\\n"\n\n        # Current task\n        if self.current_task:\n            context += f"Current task: {self.current_task}\\n"\n\n        return context\n\n    def create_rich_prompt(self, user_input, conversation_context):\n        """\n        Create a rich prompt with world state and conversation context\n        """\n        world_context = self.get_world_context()\n        full_prompt = f"{world_context}\\n{conversation_context}\\n"\n        full_prompt += f"User request: {user_input}\\n"\n        full_prompt += "Robot response with action:"\n\n        return full_prompt\n'})}),"\n",(0,s.jsx)(n.h2,{id:"safety-and-control-mechanisms",children:"Safety and Control Mechanisms"}),"\n",(0,s.jsx)(n.h3,{id:"action-validation",children:"Action Validation"}),"\n",(0,s.jsx)(n.p,{children:"Ensuring robot actions are safe and appropriate:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"class SafetyValidator:\n    def __init__(self):\n        self.forbidden_actions = [\n            'harm', 'dangerous', 'unsafe', 'inappropriate'\n        ]\n        self.safe_locations = set()\n        self.forbidden_objects = set()\n\n    def validate_action(self, action, context):\n        \"\"\"\n        Validate that an action is safe to execute\n        \"\"\"\n        # Check if action contains forbidden terms\n        action_text = str(action).lower()\n        for forbidden in self.forbidden_actions:\n            if forbidden in action_text:\n                return False, f\"Action contains forbidden term: {forbidden}\"\n\n        # Check location safety\n        if 'action' in action and action['action'] == 'navigation':\n            target = action.get('target', '')\n            if target not in self.safe_locations:\n                return False, f\"Navigation to {target} is not in safe locations\"\n\n        # Check object safety\n        if 'action' in action and action['action'] == 'manipulation':\n            target = action.get('target', '')\n            if target in self.forbidden_objects:\n                return False, f\"Manipulation of {target} is forbidden\"\n\n        # Check for harmful language\n        if 'text' in action:\n            if self.contains_harmful_language(action['text']):\n                return False, \"Response contains potentially harmful language\"\n\n        return True, \"Action is safe\"\n\n    def contains_harmful_language(self, text):\n        \"\"\"\n        Check if text contains harmful language\n        \"\"\"\n        # This would typically use a more sophisticated content filter\n        harmful_keywords = [\n            'injure', 'hurt', 'damage', 'break', 'destroy',\n            'inappropriate', 'offensive', 'harmful'\n        ]\n\n        text_lower = text.lower()\n        return any(keyword in text_lower for keyword in harmful_keywords)\n"})}),"\n",(0,s.jsx)(n.h3,{id:"response-filtering",children:"Response Filtering"}),"\n",(0,s.jsx)(n.p,{children:"Filtering LLM responses for safety:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class ResponseFilter:\n    def __init__(self):\n        self.safety_validator = SafetyValidator()\n\n    def filter_response(self, model_response, user_input):\n        """\n        Filter model response for safety and appropriateness\n        """\n        # Parse the response into actions\n        parsed_action = self.safety_validator.parse_model_response(model_response)\n\n        # Validate the action\n        is_safe, reason = self.safety_validator.validate_action(parsed_action, user_input)\n\n        if is_safe:\n            return parsed_action\n        else:\n            # Return a safe fallback response\n            return {\n                \'action\': \'speak\',\n                \'text\': "I\'m sorry, I can\'t do that. How else can I help you?",\n                \'raw_response\': model_response\n            }\n\n    def moderate_content(self, text):\n        """\n        Moderate content in responses\n        """\n        # Apply content filtering\n        if self.is_inappropriate(text):\n            return self.generate_safe_alternative(text)\n        return text\n\n    def is_inappropriate(self, text):\n        """\n        Check if text is inappropriate\n        """\n        # Simple keyword-based check (in practice, use more sophisticated methods)\n        inappropriate_keywords = [\n            \'inappropriate\', \'offensive\', \'private\', \'personal\', \'confidential\'\n        ]\n\n        text_lower = text.lower()\n        return any(keyword in text_lower for keyword in inappropriate_keywords)\n\n    def generate_safe_alternative(self, original_text):\n        """\n        Generate a safe alternative to inappropriate content\n        """\n        return "I can\'t respond to that. How else can I assist you today?"\n'})}),"\n",(0,s.jsx)(n.h2,{id:"integration-patterns",children:"Integration Patterns"}),"\n",(0,s.jsx)(n.h3,{id:"async-processing-pattern",children:"Async Processing Pattern"}),"\n",(0,s.jsx)(n.p,{children:"Handling LLM processing without blocking robot operations:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import asyncio\nimport threading\nfrom queue import Queue\n\nclass AsyncGPTProcessor:\n    def __init__(self):\n        self.request_queue = Queue()\n        self.response_queue = Queue()\n        self.model_interface = GPTRobotInterface()\n        self.is_running = False\n        self.worker_thread = None\n\n    def start_processing(self):\n        """\n        Start the async processing thread\n        """\n        self.is_running = True\n        self.worker_thread = threading.Thread(target=self._process_requests)\n        self.worker_thread.start()\n\n    def _process_requests(self):\n        """\n        Process requests in the background\n        """\n        while self.is_running:\n            try:\n                # Get request from queue\n                request = self.request_queue.get(timeout=1.0)\n\n                # Process with GPT model\n                response = self.model_interface.generate_response(request)\n\n                # Put response in output queue\n                self.response_queue.put(response)\n\n            except:\n                continue  # Timeout or other exception, continue loop\n\n    def submit_request(self, prompt):\n        """\n        Submit a request for async processing\n        """\n        self.request_queue.put(prompt)\n\n    def get_response(self, timeout=5.0):\n        """\n        Get response with timeout\n        """\n        try:\n            return self.response_queue.get(timeout=timeout)\n        except:\n            return None\n\n    def stop_processing(self):\n        """\n        Stop the processing thread\n        """\n        self.is_running = False\n        if self.worker_thread:\n            self.worker_thread.join()\n'})}),"\n",(0,s.jsx)(n.h3,{id:"context-aware-response-generation",children:"Context-Aware Response Generation"}),"\n",(0,s.jsx)(n.p,{children:"Generating responses that consider the robot's capabilities:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class ContextAwareGenerator:\n    def __init__(self):\n        self.gpt_interface = GPTRobotInterface()\n        self.world_context = WorldStateContext()\n        self.conversation_manager = ConversationManager()\n        self.safety_filter = ResponseFilter()\n\n    def generate_robot_response(self, user_input, robot_capabilities):\n        """\n        Generate a context-aware response for the robot\n        """\n        # Create rich context\n        conversation_context = self.conversation_manager.get_context_prompt()\n        world_context = self.world_context.get_world_context()\n\n        # Create prompt with all context\n        full_prompt = self.create_contextual_prompt(\n            user_input, conversation_context, world_context, robot_capabilities\n        )\n\n        # Generate response with GPT\n        raw_response = self.gpt_interface.generate_response(full_prompt)\n\n        # Parse and validate response\n        parsed_action = self.safety_filter.filter_response(raw_response, user_input)\n\n        # Update conversation history\n        self.conversation_manager.add_turn(user_input, str(parsed_action))\n\n        return parsed_action\n\n    def create_contextual_prompt(self, user_input, conv_context, world_context, capabilities):\n        """\n        Create a prompt with full contextual information\n        """\n        prompt = f"System: You are a {capabilities} humanoid robot assistant.\\n"\n        prompt += f"{world_context}\\n"\n        prompt += f"{conv_context}\\n"\n        prompt += f"User: {user_input}\\n"\n        prompt += "Provide a response with specific robot actions. If you cannot perform the requested action, explain why and suggest alternatives.\\n"\n        prompt += "Response:"\n\n        return prompt\n\n    def handle_context_switching(self, new_context):\n        """\n        Handle switching between different interaction contexts\n        """\n        # Clear or adapt conversation history\n        self.conversation_manager.conversation_history = []\n        self.conversation_manager.context_summary = ""\n\n        # Update world state\n        self.world_context = new_context\n'})}),"\n",(0,s.jsx)(n.h2,{id:"practical-implementation-considerations",children:"Practical Implementation Considerations"}),"\n",(0,s.jsx)(n.h3,{id:"latency-management",children:"Latency Management"}),"\n",(0,s.jsx)(n.p,{children:"Managing the latency of LLM responses in real-time robotics:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import time\n\nclass LatencyManager:\n    def __init__(self):\n        self.avg_response_time = 2.0  # seconds\n        self.max_acceptable_latency = 5.0  # seconds\n        self.response_times = []\n\n    def measure_response_time(self, start_time, end_time):\n        """\n        Measure and track response time\n        """\n        response_time = end_time - start_time\n        self.response_times.append(response_time)\n\n        # Update average (simple moving average)\n        if len(self.response_times) > 10:  # Keep last 10 measurements\n            self.response_times = self.response_times[-10:]\n\n        self.avg_response_time = sum(self.response_times) / len(self.response_times)\n\n    def should_use_llm(self):\n        """\n        Decide whether to use LLM based on current system load\n        """\n        return self.avg_response_time < self.max_acceptable_latency\n\n    def generate_fallback_response(self, user_input):\n        """\n        Generate a quick fallback response if LLM is too slow\n        """\n        simple_responses = {\n            \'hello\': \'Hello! How can I help you?\',\n            \'help\': \'I can help with navigation, object manipulation, and information.\',\n            \'how are you\': \'I am functioning well, thank you for asking!\',\n            \'what can you do\': \'I can navigate, manipulate objects, and have conversations.\'\n        }\n\n        user_lower = user_input.lower()\n        for key, response in simple_responses.items():\n            if key in user_lower:\n                return response\n\n        return "I\'m processing your request. Please wait a moment."\n'})}),"\n",(0,s.jsx)(n.h3,{id:"memory-management",children:"Memory Management"}),"\n",(0,s.jsx)(n.p,{children:"Managing memory for continuous conversation:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class MemoryManager:\n    def __init__(self, max_memory_mb=1000):\n        self.max_memory = max_memory_mb * 1024 * 1024  # Convert to bytes\n        self.current_memory_usage = 0\n        self.conversation_segments = []\n\n    def add_conversation_segment(self, segment):\n        """\n        Add a conversation segment to memory\n        """\n        import sys\n        segment_size = sys.getsizeof(str(segment))\n\n        if self.current_memory_usage + segment_size > self.max_memory:\n            # Remove oldest segments to make space\n            self.prune_memory(segment_size)\n\n        self.conversation_segments.append(segment)\n        self.current_memory_usage += segment_size\n\n    def prune_memory(self, needed_space):\n        """\n        Prune memory to make room for new data\n        """\n        while (self.current_memory_usage > self.max_memory * 0.7 or\n               needed_space > self.max_memory - self.current_memory_usage) and \\\n              len(self.conversation_segments) > 1:\n            removed_segment = self.conversation_segments.pop(0)\n            import sys\n            removed_size = sys.getsizeof(str(removed_segment))\n            self.current_memory_usage -= removed_size\n\n    def compress_context(self):\n        """\n        Compress conversation context to save memory\n        """\n        # Summarize long conversation histories\n        if len(self.conversation_segments) > 20:\n            # Keep recent segments, summarize older ones\n            recent = self.conversation_segments[-5:]\n            older = self.conversation_segments[:-5]\n\n            # Create summary of older segments\n            summary = self.summarize_segments(older)\n\n            self.conversation_segments = [summary] + recent\n            self.current_memory_usage = sum(\n                sys.getsizeof(str(seg)) for seg in self.conversation_segments\n            )\n\n    def summarize_segments(self, segments):\n        """\n        Summarize a list of conversation segments\n        """\n        # Simple summary - in practice, use a summarization model\n        all_text = " ".join(str(seg) for seg in segments)\n        return f"Earlier conversation summary: {all_text[:200]}..."\n'})}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"After completing this section, you should be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Integrate GPT models with humanoid robotics systems"}),"\n",(0,s.jsx)(n.li,{children:"Implement context management for conversational AI"}),"\n",(0,s.jsx)(n.li,{children:"Apply safety and validation mechanisms for LLM outputs"}),"\n",(0,s.jsx)(n.li,{children:"Design async processing patterns for real-time robotics"}),"\n",(0,s.jsx)(n.li,{children:"Create context-aware response generation systems"}),"\n",(0,s.jsx)(n.li,{children:"Manage latency and memory constraints in LLM integration"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,s.jsx)(n.p,{children:"Refer to the following code examples in the textbook repository:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"docs/static/code-examples/capstone/humanoid_capstone_template.py"})," - Template for humanoid robot integration"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Implement a GPT interface for a humanoid robot"}),"\n",(0,s.jsx)(n.li,{children:"Create a context management system for continuous conversations"}),"\n",(0,s.jsx)(n.li,{children:"Design safety validation mechanisms for LLM-generated robot actions"}),"\n",(0,s.jsx)(n.li,{children:"Implement async processing for LLM responses"}),"\n",(0,s.jsx)(n.li,{children:"Create a memory management system for long-term interactions"}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>i});var o=t(6540);const s={},r=o.createContext(s);function a(e){const n=o.useContext(r);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);